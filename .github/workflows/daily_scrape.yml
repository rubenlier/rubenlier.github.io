name: Daily homepage scrape

on:
  schedule:
    - cron: "15 6 * * *"   # 07:45 UTC daily (08:45 Amsterdam in winter)
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install httpx beautifulsoup4 pyyaml

      - name: Run scraper (debug)
        run: |
          set -euxo pipefail
          echo "Repo root:"
          ls -la
          python --version

          python scrape_homepages.py --sources sources.yaml --out headlines_latest.jsonl --per_site 20 --sleep 1.0

          echo "After run:"
          ls -la
          echo "File details:"
          test -f headlines_latest.jsonl
          python - << 'PY'
          import json
          items=[]
          with open("headlines_latest.jsonl","r",encoding="utf-8") as f:
              for line in f:
                  line=line.strip()
                  if line:
                      items.append(json.loads(line))
          print("n_items:", len(items))
          print("first title:", items[0].get("title"))
          PY


      - name: Commit and push if changed
        run: |
          set -eux
          git status
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add headlines_latest.jsonl
          git diff --cached --quiet || git commit -m "Update headlines_latest"
          git push






